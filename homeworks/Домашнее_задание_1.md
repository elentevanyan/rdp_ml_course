# Домашнее задание 1
## Задача
Решить задачу регрессии или бинарной классификации для вашего датасета.

## Задание №1: Изучить переменные и таргет.
1.	Определитесь с таргетом. Если его нет, то создайте его на основе имеющихся переменных.
2.	Изучите вашу таргетную переменную: визуализируйте её с помощью гистограммы, оцените, нужна ли предобработка. Рассчитайте описательные статистики датасета, как для числовых переменных, так и для категориальных. Изучите полученные таблицы. Есть ли что-то, что выбивается? Зафиксируйте переменные, которые нуждаются в предобработке. 
3.	Визуализируйте данные:
a.	 Проиллюстрируйте все попарные взаимосвязи sns.pairplot
b.	Визуализируйте объем затрат в зависимости от возраста. Каким образом агрегировать информацию (и агрегировать ли вообще) – на ваше усмотрение. 
c.	Рассчитайте матрицу корреляций.
d.	При необходимости, сделайте интересующие вас визуализации.

Результатом этой части являются ваши выводы о том, какие действия нужно совершить с данными. Зафиксируйте их в отдельной текстовой ячейке. 

## Задание №3: Предобработка данных.
В этой части реализуются все шаги, намеченные вами в предыдущем пункте.
К примеру, прологарифмировать данные, отфильтровать по каким-то значениям, удалить пропущенные и т.п. Все зависит от задачи, которую вы решаете.

## Задание №4: Подготовка к обучению.
1.	Для задачи регрессии:
a.	При необходимости отшкалируйте данные стандартным шкалировщиком.
2.	Для задачи классификации:
a.	Убедитесь, что у вас соблюдается баланс классов.
3.	Разбейте данные на тренировочную (80%) и тестовую части (20%)

## Задание №5: Обучение модели.

**Регрессия** 

Для модели линейной регрессии:
1.	Обучите модель линейной регрессии. Рассчитайте метрику MAE, чтобы оценить качество модели. 
2.	Убедитесь, что модель демонстрирует обобщающую способность: проведите кросс-валидацию по 5 фолдам и оцените метрику качества MAE. Рассчитайте среднее и стандартное отклонение оценок на тестовой выборке и тренировочной. Оцените (словами) обобщающую способность модели. 

Вам пригодится функция cross_validate модуля sklearn.model_selection. Вот пример ее применения: 

scores = cross_validate(your_model, X, y, cv=3,
...                         scoring=('neg_mean_squared_error'),
...                         return_train_score=True)

В полях ‘test_score’ и ‘train_score’ объекта scores будут записаны значения метрики качества на тестовой или тренировочной выборке, которая указана в параметре scoring. Обратите внимание, что в указанном примере используется MSE, только с префиксом 'neg_mean_squared_error'. Это особенность реализации всех функций для кросс-валидации в sklearn, в которых вшита логика «чем больше, тем лучше»:

greater_is_better : boolean, default=True

Whether score_func is a score function (default), meaning high is good, 
or a loss function, meaning low is good. In the latter case, the scorer 
object will sign-flip the outcome of the score_func

В то же время, оптимизируя MSE или MAE, мы придерживаемся принципа «чем меньше, тем лучше». Поэтому в кросс-валидации используются метрики 'neg_mean_squared_error' или 'neg_mean_absolute_error'.

**Классификация** 

Для модели логистической регрессии:
1.	Обучите модель логистической регрессии. Постройте матрицу ошибок, рассчитайте ROC-AUC, чтобы оценить качество модели. 
2.	Убедитесь, что модель демонстрирует обобщающую способность: проведите кросс-валидацию по 5 фолдам и оцените метрику качества ROC-AUC. Рассчитайте среднее и стандартное отклонение оценок на тестовой выборке и тренировочной. Оцените (словами) обобщающую способность модели. 

Вам пригодится функция cross_validate модуля sklearn.model_selection. Вот пример ее применения: 

scores = cross_validate(your_model, X, y, cv=3,
...                         scoring=('roc_auc'),
...                         return_train_score=True)

В полях ‘test_score’ и ‘train_score’ объекта scores будут записаны значения метрики качества на тестовой или тренировочной выборке, которая указана в параметре scoring.
