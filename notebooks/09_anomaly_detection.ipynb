{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Поиск аномалий (Anomaly Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиска аномалий решает две задачи:\n",
    "- детекция выбросов (outlier detection): нахождение атипичных точек, которые будут мешать алгоритму и потому требуют дополнительного внимания;\n",
    "- обнаружение новизны (novelty detection): нахождение точек, которые отделяются от основных данных, и сигнализируют о чем-то новом, что мы еще не знаем\n",
    "\n",
    "Мы боремся с выбросами, если удаляем или обрабатываем крайние значения. Их надо найти, чтобы при обучении алгоритм не концентрировался на них, а искал закономерности в основном наборе точек.\n",
    "\n",
    "Мы ищем новизну, когда сканируем объекты на схожесть остальным: если объект оказался отличен, мы обнаружили новое. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда задачи обнаружения аномалий маскируются как задачи обучения с учителем. При условии, что есть частичная разметка данных на аномальные и неаномальные случаи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нам данные о температурном режиме в офисе. Разметки, где аномалия, а где норма - нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ambient_temperature_system_failure.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data['value'] = (data['value'] - 32) * 5/9\n",
    "data.plot(x='timestamp', y='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистические подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Процентили и бокс-плот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ytimg.com/vi/0Bg6z9BZSMc/maxresdefault.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LQ = data['value'].quantile(0.25)\n",
    "UQ = data['value'].quantile(0.75)\n",
    "print(data.value.min(), data.value.max())\n",
    "print(LQ, UQ)\n",
    "IQR = UQ - LQ\n",
    "lower_bound = max(data.value.min(), LQ - 1.5*IQR)\n",
    "upper_bound = min(data.value.max(), UQ + 1.5*IQR)\n",
    "print(lower_bound)\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Z_i = \\frac{|x - \\mu|}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = data.value.mean()\n",
    "sigma = data.value.std()\n",
    "z_values = [np.abs(x - mu) / sigma for x in data.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(z_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML. Эллипсоидальная аппроксимация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная предпосылка - данные должны быть нормально распределены. Кроме того, нам нужно предположить, какая доля аномальных объектов в датасете - это гиперпараметр *contamination*\n",
    "\n",
    "Идея метода в том, что вокруг точек создается воображаемое эллиптическое облако. Это облако, т.н. Elliptic Envelope, - зона нормальных точек. А те, кто выпали из этого \"конверта\" - называются аномальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['value'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EllipticEnvelope(contamination=outliers_fraction)\n",
    "array = data['value'].values.reshape(-1,1)\n",
    "\n",
    "model.fit(array)\n",
    "\n",
    "data['deviation'] = model.decision_function(array)\n",
    "data['anomaly_elptc'] = model.predict(array)\n",
    "data['anomaly_elptc'] = data['anomaly_elptc'].map( {1: 0, -1: 1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['anomaly_elptc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_elptc'] == 1][['timestamp', 'value']]\n",
    "\n",
    "plt.plot(data['timestamp'], data['value'], color='blue')\n",
    "plt.scatter(a['timestamp'], a['value'], color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hours'] = data['timestamp'].dt.hour\n",
    "data['daylight'] = ((data['hours'] >= 7) & (data['hours'] <= 22)).astype(int)\n",
    "data['DayOfTheWeek'] = data['timestamp'].dt.dayofweek\n",
    "data['WeekDay'] = (data['DayOfTheWeek'] < 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flt = data[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data_flt)\n",
    "data_flt = pd.DataFrame(np_scaled)\n",
    "\n",
    "\n",
    "# знаменитый PCA\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_flt)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# повторное шкалирование двух фичей\n",
    "min_max_scaler = StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data_pca)\n",
    "data_scld = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML. Кластерные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "plt.figure(figsize= (15,8))\n",
    "for n_c in range(2,20):\n",
    "    k_means = KMeans(n_clusters = n_c)\n",
    "    k_means = k_means.fit(data_scld)\n",
    "    inertia.append(np.sqrt(k_means.inertia_))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.plot(range(2, 20), inertia, marker='s');\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('$J(C_k)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 4)\n",
    "k_means = k_means.fit(data_scld)\n",
    "data['cluster'] = k_means.predict(data_scld)\n",
    "data['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['pc1'] = data_pca[:, 0]\n",
    "data['pc2'] = data_pca[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(data['pc1'], data['pc2'], c=data['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistanceByPoint(data, model):\n",
    "    distance = pd.Series(data.shape[0])\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]]\n",
    "        distance[i] = np.linalg.norm(Xa-Xb)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = getDistanceByPoint(data_scld, k_means)\n",
    "number_of_outliers = int(outliers_fraction*len(distance))\n",
    "threshold = distance.nlargest(number_of_outliers).min()\n",
    "\n",
    "\n",
    "data['anomaly_kmeans'] = (distance >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['anomaly_kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(data['pc1'], data['pc2'], c=data['anomaly_kmeans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_kmeans'] == 1][['timestamp', 'value']]\n",
    "\n",
    "plt.plot(data['timestamp'], data['value'], color='blue')\n",
    "plt.scatter(a['timestamp'], a['value'], color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML. Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основан на наблюдении, что нормальные наблюдения имеют тенденцию скапливаться\n",
    "\n",
    "- вводится показатель локальной плотности, обратно пропорциональный средним расстоянием до  𝑘  ближайших соседей\n",
    "- попарно сравнивается с показателями соседей\n",
    "- вычисляется отношение локальной аномальности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_neighbors = 20\n",
    "model =  LocalOutlierFactor()\n",
    "data['anomaly_lof'] = pd.Series(model.fit_predict(data_flt))\n",
    "data['anomaly_lof'] = data['anomaly_lof'].map( {1: 0, -1: 1} )\n",
    "print(data['anomaly_svm'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_lof'] == 1][['timestamp', 'value']]\n",
    "\n",
    "plt.plot(data['timestamp'], data['value'], color='blue')\n",
    "plt.scatter(a['timestamp'], a['value'], color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_lof'] == 0]['value']\n",
    "b = data[data['anomaly_lof'] == 1]['value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- подвержен проблеме \"проклятия размерности\", тк основан на расстояниях\n",
    "- не может отличить скопления аномалий от нормальных точек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML. One Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://avatars.mds.yandex.net/get-zen_doc/1692094/pub_5d444f9ca660d700aeec498a_5d445006c0dcf200adbc8c0e/scale_1200'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://avatars.mds.yandex.net/get-zen_doc/56585/pub_5d444f9ca660d700aeec498a_5d445016f0d4f400ae4b367e/scale_1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu - гиперпараметр, регулирующй долю аутлайеров\n",
    "model =  OneClassSVM(nu=outliers_fraction)\n",
    "model.fit(data_flt)\n",
    "\n",
    "\n",
    "data['anomaly_svm'] = pd.Series(model.predict(data_flt))\n",
    "data['anomaly_svm'] = data['anomaly_svm'].map( {1: 0, -1: 1} )\n",
    "print(data['anomaly_svm'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_svm'] == 1][['timestamp', 'value']]\n",
    "\n",
    "plt.plot(data['timestamp'], data['value'], color='blue')\n",
    "plt.scatter(a['timestamp'], a['value'], color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomaly_svm'] == 0]['value']\n",
    "b = data[data['anomaly_svm'] == 1]['value']\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist([a,b], bins=32, stacked=True, color=['blue', 'red'], label=['normal', 'anomaly'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- вычислительно затратен и плохо масштабируется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML. Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://1.bp.blogspot.com/-_Voh6L1tL8k/Xp0rMEjbt8I/AAAAAAAAAgg/hXY_aC5erAoRUdeaS92Rp-gjsVI6l02XwCLcBGAsYHQ/s1600/isolation%2Bforest.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://blog.faradars.org/wp-content/uploads/2020/05/partition-of-Isolation-forest.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  учим на data_flt - отшкалированных данных с признакми\n",
    "model =  IsolationForest(contamination = outliers_fraction)\n",
    "model.fit(data_flt)\n",
    "\n",
    "\n",
    "data['anomay_if'] = pd.Series(model.predict(data_flt))\n",
    "data['anomay_if'] = data['anomay_if'].map( {1: 0, -1: 1} )\n",
    "print(data['anomay_if'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data['anomay_if'] == 1][['timestamp', 'value']]\n",
    "\n",
    "plt.plot(data['timestamp'], data['value'], color='blue')\n",
    "plt.scatter(a['timestamp'], a['value'], color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минусы: \n",
    "- не различает скопления аномалий"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
